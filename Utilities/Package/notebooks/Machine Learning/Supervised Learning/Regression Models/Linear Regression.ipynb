{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is a statistical method used to understand and predict the relationship between a target variable (or dependent variable) and one or more predictor variables (or independent variables). The objective is to find a line (or plane) that best fits the data points and minimizes the difference between the predicted and actual values.\n",
    "\n",
    "Key Concepts\n",
    "1. Relationship Modeling: Linear regression assumes a straight-line relationship between the predictors and the target. The model aims to describe how changes in each predictor influence the target variable.\n",
    "\n",
    "2. Single vs. Multiple Predictors:\n",
    "\n",
    "    - Simple Linear Regression involves just one predictor and is ideal for exploring how one factor affects the target.\n",
    "    - Multiple Linear Regression uses several predictors to capture more complex relationships.\n",
    "    Fitting the Line: Linear regression finds the best line by minimizing the differences (errors) between predicted values and actual observed values. This process is known as \"least squares\" fitting.\n",
    "\n",
    "3. Interpreting Coefficients:\n",
    "\n",
    "    - Each predictor has a coefficient that indicates its influence on the target variable. A positive coefficient suggests that as the predictor increases, the target variable tends to increase as well, and vice versa.\n",
    "    - The intercept is the expected value of the target variable when all predictors are zero.\n",
    "\n",
    "4. Goodness of Fit:\n",
    "\n",
    "    - R-squared (R²) is a measure of how well the model explains the variability of the target variable. An R² closer to 1 indicates a stronger relationship, meaning the predictors account for a large portion of the target’s variability.\n",
    "\n",
    "When to Use Linear Regression\n",
    "- Predicting Continuous Outcomes: Linear regression is well-suited for predicting values like house prices, sales, or any other continuous outcome.\n",
    "- Examining Relationships: It is helpful for quantifying and understanding the strength and direction of relationships between variables.\n",
    "- Interpretability: Linear regression is straightforward, making it easy to interpret and explain relationships in the data.\n",
    "\n",
    "Limitations\n",
    "- Assumes Linearity: Linear regression requires a linear relationship between predictors and the target, which may not hold in all datasets.\n",
    "- Sensitive to Outliers: Extreme values can disproportionately affect the model, potentially skewing results.\n",
    "- Multicollinearity: When predictors are highly correlated, it can be difficult to interpret their individual effects.\n",
    "\n",
    "In summary, linear regression is a simple yet powerful tool for understanding and predicting outcomes based on one or more factors. Its interpretability and ease of use make it a foundational method in both statistics and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "def LinearRegressionWithPValues(X, y):\n",
    "    \"\"\"\n",
    "    Performs linear regression using statsmodels and returns coefficients and p-values.\n",
    "    \"\"\"\n",
    "    # Add a constant term to the predictors (intercept)\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Get the summary of the regression\n",
    "    summary = model.summary()\n",
    "\n",
    "    # Get coefficients and p-values\n",
    "    coefficients = model.params\n",
    "    p_values = model.pvalues\n",
    "\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"coefficients\": coefficients,\n",
    "        \"p_values\": p_values\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      " const        -36.941920\n",
      "MedInc         0.436693\n",
      "HouseAge       0.009436\n",
      "AveRooms      -0.107322\n",
      "AveBedrms      0.645066\n",
      "Population    -0.000004\n",
      "AveOccup      -0.003787\n",
      "Latitude      -0.421314\n",
      "Longitude     -0.434514\n",
      "dtype: float64\n",
      "P-values:\n",
      " const          0.000000e+00\n",
      "MedInc         0.000000e+00\n",
      "HouseAge       3.505485e-98\n",
      "AveRooms       1.026311e-73\n",
      "AveBedrms     6.725726e-115\n",
      "Population     4.024472e-01\n",
      "AveOccup       8.303694e-15\n",
      "Latitude       0.000000e+00\n",
      "Longitude      0.000000e+00\n",
      "dtype: float64\n",
      "\n",
      "Model Summary:\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.606\n",
      "Model:                            OLS   Adj. R-squared:                  0.606\n",
      "Method:                 Least Squares   F-statistic:                     3970.\n",
      "Date:                Thu, 14 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        00:16:45   Log-Likelihood:                -22624.\n",
      "No. Observations:               20640   AIC:                         4.527e+04\n",
      "Df Residuals:                   20631   BIC:                         4.534e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -36.9419      0.659    -56.067      0.000     -38.233     -35.650\n",
      "MedInc         0.4367      0.004    104.054      0.000       0.428       0.445\n",
      "HouseAge       0.0094      0.000     21.143      0.000       0.009       0.010\n",
      "AveRooms      -0.1073      0.006    -18.235      0.000      -0.119      -0.096\n",
      "AveBedrms      0.6451      0.028     22.928      0.000       0.590       0.700\n",
      "Population -3.976e-06   4.75e-06     -0.837      0.402   -1.33e-05    5.33e-06\n",
      "AveOccup      -0.0038      0.000     -7.769      0.000      -0.005      -0.003\n",
      "Latitude      -0.4213      0.007    -58.541      0.000      -0.435      -0.407\n",
      "Longitude     -0.4345      0.008    -57.682      0.000      -0.449      -0.420\n",
      "==============================================================================\n",
      "Omnibus:                     4393.650   Durbin-Watson:                   0.885\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14087.596\n",
      "Skew:                           1.082   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.420   Cond. No.                     2.38e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.38e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = housing.target  # This is the median house value in $100,000s\n",
    "\n",
    "# Run Linear Regression with p-values\n",
    "results = LinearRegressionWithPValues(X, y)\n",
    "\n",
    "# Output results\n",
    "print(\"Coefficients:\\n\", results[\"coefficients\"])\n",
    "print(\"P-values:\\n\", results[\"p_values\"])\n",
    "print(\"\\nModel Summary:\\n\", results[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the LinearRegressionWithPValues function provides several key metrics and insights. Here’s a guide to understanding each component of the output:\n",
    "\n",
    "1. Coefficients\n",
    "    - The coefficients represent the average change in the target variable (house value) for a one-unit increase in each predictor variable, holding all other variables constant.\n",
    "    - A positive coefficient indicates that as the predictor variable increases, the house value also tends to increase.\n",
    "    - A negative coefficient suggests an inverse relationship, where an increase in the predictor variable corresponds to a decrease in house value.\n",
    "    - For example, if the coefficient for MedInc (median income) is positive, this means higher income levels are associated with higher house values.\n",
    "2. P-values\n",
    "    - P-values indicate the statistical significance of each predictor.\n",
    "    - A low p-value (typically < 0.05) suggests that the predictor is statistically significant and likely has a meaningful impact on the target variable (house value).\n",
    "    - A high p-value (typically > 0.05) implies that the predictor may not have a statistically significant effect on the target variable, meaning its contribution to predicting house value might be minimal.\n",
    "3. R² Score (R-squared)\n",
    "    - R² is the coefficient of determination and measures the proportion of variance in the target variable (house value) that is explained by the predictor variables.\n",
    "    \n",
    "        Interpretation:\n",
    "            \n",
    "        - An R² closer to 1 indicates a better fit, meaning the model explains a large portion of the variability in house values.\n",
    "\n",
    "        - An R² closer to 0 suggests a poor fit, meaning the model explains little of the variability in house values.\n",
    "    - Adjusted R²: Unlike R², adjusted R² adjusts for the number of predictors in the model and is generally more reliable, especially when working with multiple predictors.\n",
    "4. Model Summary\n",
    "    - The model summary provides an overview of the linear regression results, including:\n",
    "        - F-statistic: Tests the overall significance of the model. A high F-statistic with a low p-value suggests that the model is statistically significant as a whole.\n",
    "        - Standard Errors: Show the variability of each coefficient estimate. Larger standard errors suggest more uncertainty in the coefficient’s value.\n",
    "        - Confidence Intervals: Indicate the range within which we expect the true coefficient values to fall. Narrow intervals suggest more confidence in the estimate.\n",
    "    Example Interpretation\n",
    "    Suppose the output shows the following:\n",
    "\n",
    "    - Positive coefficient for MedInc with a low p-value: This suggests that median income has a statistically significant positive relationship with house value.\n",
    "    - Negative coefficient for HouseAge with a low p-value: This implies that as houses get older, their value tends to decrease, and this relationship is statistically significant.\n",
    "\n",
    "In summary, by analyzing coefficients, p-values, and the R² score, you can determine which features are important predictors of house value and how well the model explains the variation in house prices. This insight helps in understanding the impact of various factors, like income and house age, on property values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
